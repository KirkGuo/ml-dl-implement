{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_channel):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channel, 8, 5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(16*7*7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = self.pool(out)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = self.pool(out)\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        return self.fc2(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(root='../data', pre_process=None):\n",
    "    train_dataset = torchvision.datasets.MNIST(root, download=True, train=True, transform=pre_process)\n",
    "    test_dataset = torchvision.datasets.MNIST(root, download=True, train=False, transform=pre_process)\n",
    "        \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=64,\n",
    "        shuffle=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=1024,\n",
    "        shuffle=True\n",
    "    )\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, loss_fn, criterion, epochs=100):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        loss = 0.0\n",
    "        for idx, (data, label) in enumerate(train_loader):\n",
    "            if torch.cuda.is_available():\n",
    "                data, label = data.cuda(), label.cuda()\n",
    "            output = model(data)\n",
    "            criterion.zero_grad()\n",
    "            curr_loss = loss_fn(output, label)\n",
    "            curr_loss.backward()\n",
    "            criterion.step()\n",
    "            \n",
    "            loss += curr_loss.item()\n",
    "        \n",
    "        print('loss for epoch {} : {}'.format(epoch, loss))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(test_loader, model, loss_fn):\n",
    "    \n",
    "    loss = 0.0\n",
    "    correct = 0.0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, (data, label) in enumerate(test_loader):\n",
    "            if torch.cuda.is_available():\n",
    "                data, label = data.cuda(), label.cuda()\n",
    "            output = model(data)\n",
    "            curr_loss = loss_fn(output, label)\n",
    "            loss += curr_loss.item()\n",
    "            pred = torch.max(output, dim=1, keepdim=True)[1]\n",
    "            correct += pred.eq(label.view_as(pred)).sum()\n",
    "    \n",
    "    print('loss on test dataset : {}'.format(loss))\n",
    "    print('accuarcy : {}'.format(correct/len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch 0 : 1147.6480618864298\n",
      "loss for epoch 1 : 255.77923431247473\n",
      "loss for epoch 2 : 158.52334367111325\n",
      "loss for epoch 3 : 115.3131293617189\n",
      "loss for epoch 4 : 92.82713167369366\n",
      "loss for epoch 5 : 79.34567393362522\n",
      "loss for epoch 6 : 69.62860082089901\n",
      "loss for epoch 7 : 62.309159621596336\n",
      "loss for epoch 8 : 56.3913088850677\n",
      "loss for epoch 9 : 52.139172468334436\n",
      "loss for epoch 10 : 48.811040475964546\n",
      "loss for epoch 11 : 45.86175771802664\n",
      "loss for epoch 12 : 42.98154804855585\n",
      "loss for epoch 13 : 39.88753915950656\n",
      "loss for epoch 14 : 38.08829386904836\n",
      "loss for epoch 15 : 36.13586365431547\n",
      "loss for epoch 16 : 34.32751172967255\n",
      "loss for epoch 17 : 32.28043647110462\n",
      "loss for epoch 18 : 31.11438038945198\n",
      "loss for epoch 19 : 29.24854524806142\n",
      "loss for epoch 20 : 28.004321239888668\n",
      "loss for epoch 21 : 26.97936587035656\n",
      "loss for epoch 22 : 25.386552929878235\n",
      "loss for epoch 23 : 24.927415922284126\n",
      "loss for epoch 24 : 23.1916126832366\n",
      "loss for epoch 25 : 22.0575286783278\n",
      "loss for epoch 26 : 21.450536996126175\n",
      "loss for epoch 27 : 21.011429607868195\n",
      "loss for epoch 28 : 19.669844295829535\n",
      "loss for epoch 29 : 19.222867257893085\n",
      "loss for epoch 30 : 17.71884026378393\n",
      "loss for epoch 31 : 17.53883508592844\n",
      "loss for epoch 32 : 16.77157750353217\n",
      "loss for epoch 33 : 16.185602221637964\n",
      "loss for epoch 34 : 15.079986147582531\n",
      "loss for epoch 35 : 14.815958049148321\n",
      "loss for epoch 36 : 14.164025850594044\n",
      "loss for epoch 37 : 13.47698538005352\n",
      "loss for epoch 38 : 12.924582321196795\n",
      "loss for epoch 39 : 12.790308143943548\n",
      "loss for epoch 40 : 12.068297784775496\n",
      "loss for epoch 41 : 11.730373430997133\n",
      "loss for epoch 42 : 10.963786039501429\n",
      "loss for epoch 43 : 10.458470202982426\n",
      "loss for epoch 44 : 10.074995689094067\n",
      "loss for epoch 45 : 9.841541647911072\n",
      "loss for epoch 46 : 9.324877489358187\n",
      "loss for epoch 47 : 9.19824218377471\n",
      "loss for epoch 48 : 8.659685052931309\n",
      "loss for epoch 49 : 8.132934045046568\n",
      "loss for epoch 50 : 8.232544634491205\n",
      "loss for epoch 51 : 7.612792517989874\n",
      "loss for epoch 52 : 7.489216513931751\n",
      "loss for epoch 53 : 7.2326630018651485\n",
      "loss for epoch 54 : 6.900493238121271\n",
      "loss for epoch 55 : 6.591595623642206\n",
      "loss for epoch 56 : 6.333020623773336\n",
      "loss for epoch 57 : 6.130184128880501\n",
      "loss for epoch 58 : 5.5673612505197525\n",
      "loss for epoch 59 : 5.6256908774375916\n",
      "loss for epoch 60 : 5.318059764802456\n",
      "loss for epoch 61 : 5.168351639062166\n",
      "loss for epoch 62 : 4.926132582128048\n",
      "loss for epoch 63 : 4.66281921043992\n",
      "loss for epoch 64 : 4.38526825606823\n",
      "loss for epoch 65 : 4.347851704806089\n",
      "loss for epoch 66 : 4.358593977987766\n",
      "loss for epoch 67 : 4.0412285178899765\n",
      "loss for epoch 68 : 3.8183915466070175\n",
      "loss for epoch 69 : 3.8312257826328278\n",
      "loss for epoch 70 : 3.6238956302404404\n",
      "loss for epoch 71 : 3.4744210205972195\n",
      "loss for epoch 72 : 3.6084547266364098\n",
      "loss for epoch 73 : 3.3966478779911995\n",
      "loss for epoch 74 : 3.1256606578826904\n",
      "loss for epoch 75 : 3.016488939523697\n",
      "loss for epoch 76 : 2.893633112311363\n",
      "loss for epoch 77 : 2.655177064239979\n",
      "loss for epoch 78 : 2.5517512634396553\n",
      "loss for epoch 79 : 2.475046969950199\n",
      "loss for epoch 80 : 2.4337855502963066\n",
      "loss for epoch 81 : 2.2347334772348404\n",
      "loss for epoch 82 : 2.4674634858965874\n",
      "loss for epoch 83 : 2.0589331835508347\n",
      "loss for epoch 84 : 1.9586065113544464\n",
      "loss for epoch 85 : 1.8839562386274338\n",
      "loss for epoch 86 : 1.9000150933861732\n",
      "loss for epoch 87 : 1.9847476109862328\n",
      "loss for epoch 88 : 1.8970334008336067\n",
      "loss for epoch 89 : 1.9776981472969055\n",
      "loss for epoch 90 : 1.6440274342894554\n",
      "loss for epoch 91 : 1.6839510053396225\n",
      "loss for epoch 92 : 1.4582026824355125\n",
      "loss for epoch 93 : 1.4873217195272446\n",
      "loss for epoch 94 : 1.4477738589048386\n",
      "loss for epoch 95 : 1.4036109372973442\n",
      "loss for epoch 96 : 1.2364492565393448\n",
      "loss for epoch 97 : 1.1795497462153435\n",
      "loss for epoch 98 : 1.380689449608326\n",
      "loss for epoch 99 : 1.073033906519413\n",
      "loss on test dataset : 0.4428468346595764\n",
      "accuarcy : 0.9888999462127686\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    \n",
    "    pre_process = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ])\n",
    "    train_data, test_data = load_data(pre_process=pre_process)\n",
    "    \n",
    "    model = Model(1)\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    criterion = optim.SGD(model.parameters(), lr=0.01)\n",
    "    \n",
    "    model = train(train_data, model, loss_fn, criterion)\n",
    "    \n",
    "    eval(test_data, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
